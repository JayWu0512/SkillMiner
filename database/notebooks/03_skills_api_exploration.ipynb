{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13d3c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to explore GitHub API!\n",
      "Authentication: ‚úì Enabled\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 1: Install and import dependencies\n",
    "# !pip install requests pandas python-dotenv\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "print(\"Ready to explore GitHub API!\")\n",
    "print(f\"Authentication: {'‚úì Enabled' if GITHUB_TOKEN else '‚úó Disabled (60 req/hour limit)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e93e9930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Rate Limit Status ===\n",
      "Core API: 5000/5000 remaining\n",
      "Search API: 30/30 remaining\n",
      "Resets at: 2025-11-11 12:30:16\n"
     ]
    }
   ],
   "source": [
    "def check_rate_limit():\n",
    "    \"\"\"Check current API rate limit status\"\"\"\n",
    "    url = \"https://api.github.com/rate_limit\"\n",
    "    \n",
    "    headers = {}\n",
    "    if GITHUB_TOKEN:\n",
    "        headers['Authorization'] = f'token {GITHUB_TOKEN}'\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "    \n",
    "    core = data['resources']['core']\n",
    "    search = data['resources']['search']\n",
    "    \n",
    "    print(\"=== Rate Limit Status ===\")\n",
    "    print(f\"Core API: {core['remaining']}/{core['limit']} remaining\")\n",
    "    print(f\"Search API: {search['remaining']}/{search['limit']} remaining\")\n",
    "    print(f\"Resets at: {datetime.fromtimestamp(core['reset'])}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "rate_info = check_rate_limit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17579769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count: 360,435\n",
      "Returned: 5 repos\n",
      "\n",
      "1. labmlai/annotated_deep_learning_paper_implementations\n",
      "   ‚≠ê 64,241 stars | üç¥ 6,515 forks\n",
      "   https://github.com/labmlai/annotated_deep_learning_paper_implementations\n",
      "\n",
      "2. keras-team/keras\n",
      "   ‚≠ê 63,551 stars | üç¥ 19,646 forks\n",
      "   https://github.com/keras-team/keras\n",
      "\n",
      "3. scutan90/DeepLearning-500-questions\n",
      "   ‚≠ê 56,805 stars | üç¥ 15,974 forks\n",
      "   https://github.com/scutan90/DeepLearning-500-questions\n",
      "\n",
      "4. coqui-ai/TTS\n",
      "   ‚≠ê 43,400 stars | üç¥ 5,752 forks\n",
      "   https://github.com/coqui-ai/TTS\n",
      "\n",
      "5. deepspeedai/DeepSpeed\n",
      "   ‚≠ê 40,664 stars | üç¥ 4,620 forks\n",
      "   https://github.com/deepspeedai/DeepSpeed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Search for repositories by skill/keyword\n",
    "def search_repos(query, sort='stars', per_page=10):\n",
    "    \"\"\"\n",
    "    Search GitHub repositories\n",
    "    \n",
    "    Args:\n",
    "        query: Search query (e.g., 'deep learning', 'react', 'python')\n",
    "        sort: 'stars', 'forks', 'updated', 'help-wanted-issues'\n",
    "        per_page: Number of results (max 100)\n",
    "    \"\"\"\n",
    "    url = \"https://api.github.com/search/repositories\"\n",
    "    \n",
    "    params = {\n",
    "        'q': query,\n",
    "        'sort': sort,\n",
    "        'order': 'desc',\n",
    "        'per_page': per_page\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'Accept': 'application/vnd.github.v3+json'\n",
    "    }\n",
    "    \n",
    "    if GITHUB_TOKEN:\n",
    "        headers['Authorization'] = f'token {GITHUB_TOKEN}'\n",
    "    \n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(response.json())\n",
    "        return None\n",
    "\n",
    "# Try searching for \"deep learning\"\n",
    "results = search_repos('deep learning', per_page=5)\n",
    "\n",
    "if results:\n",
    "    print(f\"Total count: {results['total_count']:,}\")\n",
    "    print(f\"Returned: {len(results['items'])} repos\\n\")\n",
    "    \n",
    "    for i, repo in enumerate(results['items'], 1):\n",
    "        print(f\"{i}. {repo['full_name']}\")\n",
    "        print(f\"   ‚≠ê {repo['stargazers_count']:,} stars | üç¥ {repo['forks_count']:,} forks\")\n",
    "        print(f\"   {repo['html_url']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cb874f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>owner</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>stars</th>\n",
       "      <th>forks</th>\n",
       "      <th>watchers</th>\n",
       "      <th>language</th>\n",
       "      <th>topics</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>size</th>\n",
       "      <th>open_issues</th>\n",
       "      <th>license</th>\n",
       "      <th>default_branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>labmlai/annotated_deep_learning_paper_implemen...</td>\n",
       "      <td>labmlai</td>\n",
       "      <td>annotated_deep_learning_paper_implementations</td>\n",
       "      <td>https://github.com/labmlai/annotated_deep_lear...</td>\n",
       "      <td>üßë‚Äçüè´ 60+ Implementations/tutorials of deep lear...</td>\n",
       "      <td>64241</td>\n",
       "      <td>6515</td>\n",
       "      <td>64241</td>\n",
       "      <td>Python</td>\n",
       "      <td>attention, deep-learning, deep-learning-tutori...</td>\n",
       "      <td>2020-08-25 02:29:34+00:00</td>\n",
       "      <td>2025-11-11 13:50:56+00:00</td>\n",
       "      <td>156359</td>\n",
       "      <td>27</td>\n",
       "      <td>MIT License</td>\n",
       "      <td>master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>keras-team/keras</td>\n",
       "      <td>keras-team</td>\n",
       "      <td>keras</td>\n",
       "      <td>https://github.com/keras-team/keras</td>\n",
       "      <td>Deep Learning for humans</td>\n",
       "      <td>63551</td>\n",
       "      <td>19646</td>\n",
       "      <td>63551</td>\n",
       "      <td>Python</td>\n",
       "      <td>data-science, deep-learning, jax, machine-lear...</td>\n",
       "      <td>2015-03-28 00:35:42+00:00</td>\n",
       "      <td>2025-11-11 13:59:20+00:00</td>\n",
       "      <td>48578</td>\n",
       "      <td>270</td>\n",
       "      <td>Apache License 2.0</td>\n",
       "      <td>master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scutan90/DeepLearning-500-questions</td>\n",
       "      <td>scutan90</td>\n",
       "      <td>DeepLearning-500-questions</td>\n",
       "      <td>https://github.com/scutan90/DeepLearning-500-q...</td>\n",
       "      <td>Ê∑±Â∫¶Â≠¶‰π†500ÈóÆÔºå‰ª•ÈóÆÁ≠îÂΩ¢ÂºèÂØπÂ∏∏Áî®ÁöÑÊ¶ÇÁéáÁü•ËØÜ„ÄÅÁ∫øÊÄß‰ª£Êï∞„ÄÅÊú∫Âô®Â≠¶‰π†„ÄÅÊ∑±Â∫¶Â≠¶‰π†„ÄÅËÆ°ÁÆóÊú∫ËßÜËßâÁ≠âÁÉ≠ÁÇπ...</td>\n",
       "      <td>56805</td>\n",
       "      <td>15974</td>\n",
       "      <td>56805</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td></td>\n",
       "      <td>2018-06-27 06:36:45+00:00</td>\n",
       "      <td>2025-11-11 13:03:13+00:00</td>\n",
       "      <td>207074</td>\n",
       "      <td>120</td>\n",
       "      <td>GNU General Public License v3.0</td>\n",
       "      <td>master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coqui-ai/TTS</td>\n",
       "      <td>coqui-ai</td>\n",
       "      <td>TTS</td>\n",
       "      <td>https://github.com/coqui-ai/TTS</td>\n",
       "      <td>üê∏üí¨ - a deep learning toolkit for Text-to-Speec...</td>\n",
       "      <td>43400</td>\n",
       "      <td>5752</td>\n",
       "      <td>43400</td>\n",
       "      <td>Python</td>\n",
       "      <td>deep-learning, glow-tts, hifigan, melgan, mult...</td>\n",
       "      <td>2020-05-20 15:45:28+00:00</td>\n",
       "      <td>2025-11-11 12:51:53+00:00</td>\n",
       "      <td>170196</td>\n",
       "      <td>12</td>\n",
       "      <td>Mozilla Public License 2.0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deepspeedai/DeepSpeed</td>\n",
       "      <td>deepspeedai</td>\n",
       "      <td>DeepSpeed</td>\n",
       "      <td>https://github.com/deepspeedai/DeepSpeed</td>\n",
       "      <td>DeepSpeed is a deep learning optimization libr...</td>\n",
       "      <td>40664</td>\n",
       "      <td>4620</td>\n",
       "      <td>40664</td>\n",
       "      <td>Python</td>\n",
       "      <td>billion-parameters, compression, data-parallel...</td>\n",
       "      <td>2020-01-23 18:35:18+00:00</td>\n",
       "      <td>2025-11-11 12:49:29+00:00</td>\n",
       "      <td>243444</td>\n",
       "      <td>1237</td>\n",
       "      <td>Apache License 2.0</td>\n",
       "      <td>master</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_name        owner  \\\n",
       "0  labmlai/annotated_deep_learning_paper_implemen...      labmlai   \n",
       "1                                   keras-team/keras   keras-team   \n",
       "2                scutan90/DeepLearning-500-questions     scutan90   \n",
       "3                                       coqui-ai/TTS     coqui-ai   \n",
       "4                              deepspeedai/DeepSpeed  deepspeedai   \n",
       "\n",
       "                                            name  \\\n",
       "0  annotated_deep_learning_paper_implementations   \n",
       "1                                          keras   \n",
       "2                     DeepLearning-500-questions   \n",
       "3                                            TTS   \n",
       "4                                      DeepSpeed   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://github.com/labmlai/annotated_deep_lear...   \n",
       "1                https://github.com/keras-team/keras   \n",
       "2  https://github.com/scutan90/DeepLearning-500-q...   \n",
       "3                    https://github.com/coqui-ai/TTS   \n",
       "4           https://github.com/deepspeedai/DeepSpeed   \n",
       "\n",
       "                                         description  stars  forks  watchers  \\\n",
       "0  üßë‚Äçüè´ 60+ Implementations/tutorials of deep lear...  64241   6515     64241   \n",
       "1                           Deep Learning for humans  63551  19646     63551   \n",
       "2  Ê∑±Â∫¶Â≠¶‰π†500ÈóÆÔºå‰ª•ÈóÆÁ≠îÂΩ¢ÂºèÂØπÂ∏∏Áî®ÁöÑÊ¶ÇÁéáÁü•ËØÜ„ÄÅÁ∫øÊÄß‰ª£Êï∞„ÄÅÊú∫Âô®Â≠¶‰π†„ÄÅÊ∑±Â∫¶Â≠¶‰π†„ÄÅËÆ°ÁÆóÊú∫ËßÜËßâÁ≠âÁÉ≠ÁÇπ...  56805  15974     56805   \n",
       "3  üê∏üí¨ - a deep learning toolkit for Text-to-Speec...  43400   5752     43400   \n",
       "4  DeepSpeed is a deep learning optimization libr...  40664   4620     40664   \n",
       "\n",
       "     language                                             topics  \\\n",
       "0      Python  attention, deep-learning, deep-learning-tutori...   \n",
       "1      Python  data-science, deep-learning, jax, machine-lear...   \n",
       "2  JavaScript                                                      \n",
       "3      Python  deep-learning, glow-tts, hifigan, melgan, mult...   \n",
       "4      Python  billion-parameters, compression, data-parallel...   \n",
       "\n",
       "                 created_at                updated_at    size  open_issues  \\\n",
       "0 2020-08-25 02:29:34+00:00 2025-11-11 13:50:56+00:00  156359           27   \n",
       "1 2015-03-28 00:35:42+00:00 2025-11-11 13:59:20+00:00   48578          270   \n",
       "2 2018-06-27 06:36:45+00:00 2025-11-11 13:03:13+00:00  207074          120   \n",
       "3 2020-05-20 15:45:28+00:00 2025-11-11 12:51:53+00:00  170196           12   \n",
       "4 2020-01-23 18:35:18+00:00 2025-11-11 12:49:29+00:00  243444         1237   \n",
       "\n",
       "                           license default_branch  \n",
       "0                      MIT License         master  \n",
       "1               Apache License 2.0         master  \n",
       "2  GNU General Public License v3.0         master  \n",
       "3       Mozilla Public License 2.0            dev  \n",
       "4               Apache License 2.0         master  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4 (Fixed): Extract useful information into a DataFrame\n",
    "def repos_to_dataframe(search_results):\n",
    "    \"\"\"Convert search results to a clean DataFrame\"\"\"\n",
    "    \n",
    "    if not search_results or 'items' not in search_results:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    items = search_results.get('items', [])\n",
    "    \n",
    "    if len(items) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    repos_data = []\n",
    "    \n",
    "    for repo in items:\n",
    "        repos_data.append({\n",
    "            'full_name': repo['full_name'],\n",
    "            'owner': repo['owner']['login'],\n",
    "            'name': repo['name'],\n",
    "            'url': repo['html_url'],\n",
    "            'description': repo.get('description', ''),\n",
    "            'stars': repo['stargazers_count'],\n",
    "            'forks': repo['forks_count'],\n",
    "            'watchers': repo['watchers_count'],\n",
    "            'language': repo.get('language', 'Unknown'),\n",
    "            'topics': ', '.join(repo.get('topics', [])),\n",
    "            'created_at': repo['created_at'],\n",
    "            'updated_at': repo['updated_at'],\n",
    "            'size': repo['size'],  # KB\n",
    "            'open_issues': repo['open_issues_count'],\n",
    "            'license': repo['license']['name'] if repo.get('license') else 'No license',\n",
    "            'default_branch': repo.get('default_branch', 'main')\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(repos_data)\n",
    "    \n",
    "    # Only convert dates if DataFrame is not empty\n",
    "    if not df.empty:\n",
    "        # Convert dates\n",
    "        df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "        df['updated_at'] = pd.to_datetime(df['updated_at'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create DataFrame\n",
    "df = repos_to_dataframe(results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a85cc945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Exploring: machine learning\n",
      "\n",
      "Strategy 1: Simple keyword search\n",
      "Strategy 2: Targeted search (name, description, topics)\n",
      "\n",
      "=== Simple Search Top 5 ===\n",
      "                               full_name   stars          language\n",
      "0                  tensorflow/tensorflow  192401               C++\n",
      "1               huggingface/transformers  152398            Python\n",
      "2             microsoft/ML-For-Beginners   78815  Jupyter Notebook\n",
      "3                  fighting41love/funNLP   77132            Python\n",
      "4  josephmisiti/awesome-machine-learning   70563            Python\n",
      "\n",
      "=== Targeted Search Top 5 ===\n",
      "                               full_name   stars  \\\n",
      "0                  tensorflow/tensorflow  192401   \n",
      "1               huggingface/transformers  152398   \n",
      "2             microsoft/ML-For-Beginners   78815   \n",
      "3                  fighting41love/funNLP   77132   \n",
      "4  josephmisiti/awesome-machine-learning   70563   \n",
      "\n",
      "                                              topics  \n",
      "0  deep-learning, deep-neural-networks, distribut...  \n",
      "1  audio, deep-learning, deepseek, gemma, glm, ha...  \n",
      "2  data-science, education, machine-learning, mac...  \n",
      "3                                                     \n",
      "4                                                     \n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Explore different search strategies\n",
    "def explore_skill(skill_name, num_results=20):\n",
    "    \"\"\"Deep dive into a specific skill\"\"\"\n",
    "    \n",
    "    print(f\"üîç Exploring: {skill_name}\\n\")\n",
    "    \n",
    "    # Strategy 1: Simple keyword search\n",
    "    print(\"Strategy 1: Simple keyword search\")\n",
    "    simple = search_repos(skill_name, per_page=num_results)\n",
    "    df_simple = repos_to_dataframe(simple)\n",
    "    \n",
    "    # Strategy 2: Search in name, description, and topics\n",
    "    print(\"Strategy 2: Targeted search (name, description, topics)\")\n",
    "    targeted_query = f'{skill_name} in:name,description,topics'\n",
    "    targeted = search_repos(targeted_query, per_page=num_results)\n",
    "    df_targeted = repos_to_dataframe(targeted)\n",
    "    \n",
    "    # Strategy 3: Filter by language if applicable\n",
    "    if skill_name.lower() in ['python', 'javascript', 'java', 'go', 'rust']:\n",
    "        print(f\"Strategy 3: Language-specific search\")\n",
    "        lang_query = f'language:{skill_name}'\n",
    "        lang_results = search_repos(lang_query, per_page=num_results)\n",
    "        df_lang = repos_to_dataframe(lang_results)\n",
    "    else:\n",
    "        df_lang = pd.DataFrame()\n",
    "    \n",
    "    return {\n",
    "        'simple': df_simple,\n",
    "        'targeted': df_targeted,\n",
    "        'language': df_lang\n",
    "    }\n",
    "\n",
    "# Test with a skill from your database\n",
    "skill_results = explore_skill('machine learning', num_results=10)\n",
    "\n",
    "print(\"\\n=== Simple Search Top 5 ===\")\n",
    "print(skill_results['simple'][['full_name', 'stars', 'language']].head())\n",
    "\n",
    "print(\"\\n=== Targeted Search Top 5 ===\")\n",
    "print(skill_results['targeted'][['full_name', 'stars', 'topics']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75db3c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository: tensorflow/tensorflow\n",
      "Description: An Open Source Machine Learning Framework for Everyone\n",
      "Stars: 192,401\n",
      "Forks: 74,977\n",
      "Language: C++\n",
      "Topics: deep-learning, deep-neural-networks, distributed, machine-learning, ml, neural-network, python, tensorflow\n",
      "Homepage: https://tensorflow.org\n",
      "Has Wiki: False\n",
      "Has Issues: True\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Get detailed information about a specific repository\n",
    "def get_repo_details(owner, repo_name):\n",
    "    \"\"\"Get detailed information about a specific repository\"\"\"\n",
    "    \n",
    "    url = f\"https://api.github.com/repos/{owner}/{repo_name}\"\n",
    "    \n",
    "    headers = {\n",
    "        'Accept': 'application/vnd.github.v3+json'\n",
    "    }\n",
    "    \n",
    "    if GITHUB_TOKEN:\n",
    "        headers['Authorization'] = f'token {GITHUB_TOKEN}'\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Get details for a specific repo\n",
    "repo_details = get_repo_details('tensorflow', 'tensorflow')\n",
    "\n",
    "if repo_details:\n",
    "    print(f\"Repository: {repo_details['full_name']}\")\n",
    "    print(f\"Description: {repo_details['description']}\")\n",
    "    print(f\"Stars: {repo_details['stargazers_count']:,}\")\n",
    "    print(f\"Forks: {repo_details['forks_count']:,}\")\n",
    "    print(f\"Language: {repo_details['language']}\")\n",
    "    print(f\"Topics: {', '.join(repo_details.get('topics', []))}\")\n",
    "    print(f\"Homepage: {repo_details.get('homepage', 'N/A')}\")\n",
    "    print(f\"Has Wiki: {repo_details['has_wiki']}\")\n",
    "    print(f\"Has Issues: {repo_details['has_issues']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88d0d18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for: python...\n",
      "Searching for: javascript...\n",
      "Searching for: react...\n",
      "Searching for: machine learning...\n",
      "Searching for: docker...\n",
      "\n",
      "Total repos found: 15\n",
      "\n",
      "Sample of results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_skill</th>\n",
       "      <th>full_name</th>\n",
       "      <th>stars</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>donnemartin/system-design-primer</td>\n",
       "      <td>326153</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>python</td>\n",
       "      <td>vinta/awesome-python</td>\n",
       "      <td>268783</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>python</td>\n",
       "      <td>practical-tutorials/project-based-learning</td>\n",
       "      <td>249544</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>javascript</td>\n",
       "      <td>freeCodeCamp/freeCodeCamp</td>\n",
       "      <td>431581</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>javascript</td>\n",
       "      <td>practical-tutorials/project-based-learning</td>\n",
       "      <td>249544</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>javascript</td>\n",
       "      <td>facebook/react</td>\n",
       "      <td>240505</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>react</td>\n",
       "      <td>freeCodeCamp/freeCodeCamp</td>\n",
       "      <td>431581</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>react</td>\n",
       "      <td>facebook/react</td>\n",
       "      <td>240505</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>react</td>\n",
       "      <td>vercel/next.js</td>\n",
       "      <td>135599</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>tensorflow/tensorflow</td>\n",
       "      <td>192401</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       search_skill                                   full_name   stars  \\\n",
       "0            python            donnemartin/system-design-primer  326153   \n",
       "1            python                        vinta/awesome-python  268783   \n",
       "2            python  practical-tutorials/project-based-learning  249544   \n",
       "3        javascript                   freeCodeCamp/freeCodeCamp  431581   \n",
       "4        javascript  practical-tutorials/project-based-learning  249544   \n",
       "5        javascript                              facebook/react  240505   \n",
       "6             react                   freeCodeCamp/freeCodeCamp  431581   \n",
       "7             react                              facebook/react  240505   \n",
       "8             react                              vercel/next.js  135599   \n",
       "9  machine learning                       tensorflow/tensorflow  192401   \n",
       "\n",
       "     language  \n",
       "0      Python  \n",
       "1      Python  \n",
       "2        None  \n",
       "3  TypeScript  \n",
       "4        None  \n",
       "5  JavaScript  \n",
       "6  TypeScript  \n",
       "7  JavaScript  \n",
       "8  JavaScript  \n",
       "9         C++  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7: Batch search multiple skills\n",
    "def batch_search_skills(skills, top_n=5):\n",
    "    \"\"\"Search for multiple skills and compile results\"\"\"\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for skill in skills:\n",
    "        print(f\"Searching for: {skill}...\")\n",
    "        results = search_repos(skill, per_page=top_n)\n",
    "        df = repos_to_dataframe(results)\n",
    "        df['search_skill'] = skill  # Track which skill this came from\n",
    "        all_results[skill] = df\n",
    "    \n",
    "    # Combine all results\n",
    "    combined_df = pd.concat(all_results.values(), ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Get skills from your database (simulated here)\n",
    "sample_skills = [\n",
    "    'python',\n",
    "    'javascript', \n",
    "    'react',\n",
    "    'machine learning',\n",
    "    'docker'\n",
    "]\n",
    "\n",
    "batch_results = batch_search_skills(sample_skills, top_n=3)\n",
    "print(f\"\\nTotal repos found: {len(batch_results)}\")\n",
    "print(\"\\nSample of results:\")\n",
    "batch_results[['search_skill', 'full_name', 'stars', 'language']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bd9a106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Repository Analysis ===\n",
      "\n",
      "Top Languages:\n",
      "language\n",
      "Python              4\n",
      "JavaScript          3\n",
      "TypeScript          2\n",
      "C++                 1\n",
      "Jupyter Notebook    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Star Statistics:\n",
      "count        15.000000\n",
      "mean     222797.600000\n",
      "std      112791.728385\n",
      "min       78815.000000\n",
      "25%      143998.500000\n",
      "50%      240505.000000\n",
      "75%      259163.500000\n",
      "max      431581.000000\n",
      "Name: stars, dtype: float64\n",
      "\n",
      "Top Topics:\n",
      "python              8\n",
      "javascript          6\n",
      "react               5\n",
      "machine-learning    3\n",
      "programming         3\n",
      "education           3\n",
      "nodejs              2\n",
      "certification       2\n",
      "curriculum          2\n",
      "d3                  2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Update Recency (days since last update):\n",
      "count    15.0\n",
      "mean      0.0\n",
      "std       0.0\n",
      "min       0.0\n",
      "25%       0.0\n",
      "50%       0.0\n",
      "75%       0.0\n",
      "max       0.0\n",
      "Name: days_since_update, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Analyze what makes a good learning resource\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def analyze_repos(df):\n",
    "    \"\"\"Analyze repository characteristics\"\"\"\n",
    "    \n",
    "    print(\"=== Repository Analysis ===\\n\")\n",
    "    \n",
    "    # Language distribution\n",
    "    print(\"Top Languages:\")\n",
    "    print(df['language'].value_counts().head())\n",
    "    print()\n",
    "    \n",
    "    # Star distribution\n",
    "    print(\"Star Statistics:\")\n",
    "    print(df['stars'].describe())\n",
    "    print()\n",
    "    \n",
    "    # Most common topics\n",
    "    all_topics = []\n",
    "    for topics in df['topics'].dropna():\n",
    "        if topics:\n",
    "            all_topics.extend(topics.split(', '))\n",
    "    \n",
    "    topics_series = pd.Series(all_topics)\n",
    "    print(\"Top Topics:\")\n",
    "    print(topics_series.value_counts().head(10))\n",
    "    print()\n",
    "    \n",
    "    # Freshness (recently updated)\n",
    "    # FIX: Use timezone-aware datetime\n",
    "    now = datetime.now(timezone.utc)  # ‚Üê Changed this line\n",
    "    df['days_since_update'] = (now - df['updated_at']).dt.days\n",
    "    print(\"Update Recency (days since last update):\")\n",
    "    print(df['days_since_update'].describe())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Analyze the batch results\n",
    "analyzed = analyze_repos(batch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f921a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original repos: 15\n",
      "After quality filter: 15\n",
      "Filtered out: 0 repos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>stars</th>\n",
       "      <th>days_since_update</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>freeCodeCamp/freeCodeCamp</td>\n",
       "      <td>431581</td>\n",
       "      <td>0</td>\n",
       "      <td>careers, certification, community, curriculum,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>freeCodeCamp/freeCodeCamp</td>\n",
       "      <td>431581</td>\n",
       "      <td>0</td>\n",
       "      <td>careers, certification, community, curriculum,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>donnemartin/system-design-primer</td>\n",
       "      <td>326153</td>\n",
       "      <td>0</td>\n",
       "      <td>design, design-patterns, design-system, develo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vinta/awesome-python</td>\n",
       "      <td>268783</td>\n",
       "      <td>0</td>\n",
       "      <td>awesome, collections, python, python-framework...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>practical-tutorials/project-based-learning</td>\n",
       "      <td>249544</td>\n",
       "      <td>0</td>\n",
       "      <td>beginner-project, cpp, golang, javascript, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>practical-tutorials/project-based-learning</td>\n",
       "      <td>249544</td>\n",
       "      <td>0</td>\n",
       "      <td>beginner-project, cpp, golang, javascript, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>facebook/react</td>\n",
       "      <td>240505</td>\n",
       "      <td>0</td>\n",
       "      <td>declarative, frontend, javascript, library, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>facebook/react</td>\n",
       "      <td>240505</td>\n",
       "      <td>0</td>\n",
       "      <td>declarative, frontend, javascript, library, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tensorflow/tensorflow</td>\n",
       "      <td>192401</td>\n",
       "      <td>0</td>\n",
       "      <td>deep-learning, deep-neural-networks, distribut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ohmyzsh/ohmyzsh</td>\n",
       "      <td>182663</td>\n",
       "      <td>0</td>\n",
       "      <td>cli, cli-app, oh-my-zsh, oh-my-zsh-plugin, oh-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     full_name   stars  days_since_update  \\\n",
       "3                    freeCodeCamp/freeCodeCamp  431581                  0   \n",
       "6                    freeCodeCamp/freeCodeCamp  431581                  0   \n",
       "0             donnemartin/system-design-primer  326153                  0   \n",
       "1                         vinta/awesome-python  268783                  0   \n",
       "2   practical-tutorials/project-based-learning  249544                  0   \n",
       "4   practical-tutorials/project-based-learning  249544                  0   \n",
       "5                               facebook/react  240505                  0   \n",
       "7                               facebook/react  240505                  0   \n",
       "9                        tensorflow/tensorflow  192401                  0   \n",
       "12                             ohmyzsh/ohmyzsh  182663                  0   \n",
       "\n",
       "                                               topics  \n",
       "3   careers, certification, community, curriculum,...  \n",
       "6   careers, certification, community, curriculum,...  \n",
       "0   design, design-patterns, design-system, develo...  \n",
       "1   awesome, collections, python, python-framework...  \n",
       "2   beginner-project, cpp, golang, javascript, pro...  \n",
       "4   beginner-project, cpp, golang, javascript, pro...  \n",
       "5   declarative, frontend, javascript, library, re...  \n",
       "7   declarative, frontend, javascript, library, re...  \n",
       "9   deep-learning, deep-neural-networks, distribut...  \n",
       "12  cli, cli-app, oh-my-zsh, oh-my-zsh-plugin, oh-...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 9: Filter for \"good learning resources\"\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def filter_quality_repos(df, min_stars=100, max_age_days=365, has_topics=True):\n",
    "    \"\"\"\n",
    "    Filter for high-quality learning resources\n",
    "    \n",
    "    Criteria:\n",
    "    - Minimum star count (popular)\n",
    "    - Recently updated (maintained)\n",
    "    - Has topics (well-documented)\n",
    "    - Has description (clear purpose)\n",
    "    \"\"\"\n",
    "    \n",
    "    filtered = df.copy()\n",
    "    \n",
    "    # Filter by stars\n",
    "    filtered = filtered[filtered['stars'] >= min_stars]\n",
    "    \n",
    "    # Filter by recency\n",
    "    if 'days_since_update' not in filtered.columns:\n",
    "        now = datetime.now(timezone.utc)\n",
    "        filtered['days_since_update'] = (now - filtered['updated_at']).dt.days\n",
    "    filtered = filtered[filtered['days_since_update'] <= max_age_days]\n",
    "    \n",
    "    # Filter by topics\n",
    "    if has_topics:\n",
    "        filtered = filtered[filtered['topics'].str.len() > 0]\n",
    "    \n",
    "    # Filter by description\n",
    "    filtered = filtered[filtered['description'].str.len() > 10]\n",
    "    \n",
    "    print(f\"Original repos: {len(df)}\")\n",
    "    print(f\"After quality filter: {len(filtered)}\")\n",
    "    print(f\"Filtered out: {len(df) - len(filtered)} repos\")\n",
    "    \n",
    "    return filtered.sort_values('stars', ascending=False)\n",
    "\n",
    "quality_repos = filter_quality_repos(batch_results, min_stars=500)\n",
    "quality_repos[['full_name', 'stars', 'days_since_update', 'topics']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43394d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Deep Learning in:name,description,topics\n",
      "Query: Deep Learning tutorial\n",
      "Query: Deep Learning awesome\n",
      "\n",
      "Found 12 unique repos for 'Deep Learning'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>stars</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>labmlai/annotated_deep_learning_paper_implemen...</td>\n",
       "      <td>64241</td>\n",
       "      <td>Deep Learning in:name,description,topics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>keras-team/keras</td>\n",
       "      <td>63551</td>\n",
       "      <td>Deep Learning in:name,description,topics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scutan90/DeepLearning-500-questions</td>\n",
       "      <td>56805</td>\n",
       "      <td>Deep Learning in:name,description,topics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coqui-ai/TTS</td>\n",
       "      <td>43400</td>\n",
       "      <td>Deep Learning in:name,description,topics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deepspeedai/DeepSpeed</td>\n",
       "      <td>40664</td>\n",
       "      <td>Deep Learning in:name,description,topics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yunjey/pytorch-tutorial</td>\n",
       "      <td>31912</td>\n",
       "      <td>Deep Learning tutorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ChristosChristofidis/awesome-deep-learning</td>\n",
       "      <td>26518</td>\n",
       "      <td>Deep Learning tutorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ujjwalkarn/Machine-Learning-Tutorials</td>\n",
       "      <td>17131</td>\n",
       "      <td>Deep Learning tutorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mikoto10032/DeepLearning</td>\n",
       "      <td>16803</td>\n",
       "      <td>Deep Learning tutorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ashishpatel26/500-AI-Machine-learning-Deep-lea...</td>\n",
       "      <td>28692</td>\n",
       "      <td>Deep Learning awesome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            full_name  stars  \\\n",
       "0   labmlai/annotated_deep_learning_paper_implemen...  64241   \n",
       "1                                    keras-team/keras  63551   \n",
       "2                 scutan90/DeepLearning-500-questions  56805   \n",
       "3                                        coqui-ai/TTS  43400   \n",
       "4                               deepspeedai/DeepSpeed  40664   \n",
       "6                             yunjey/pytorch-tutorial  31912   \n",
       "7          ChristosChristofidis/awesome-deep-learning  26518   \n",
       "8               ujjwalkarn/Machine-Learning-Tutorials  17131   \n",
       "9                            Mikoto10032/DeepLearning  16803   \n",
       "10  ashishpatel26/500-AI-Machine-learning-Deep-lea...  28692   \n",
       "\n",
       "                                  query_used  \n",
       "0   Deep Learning in:name,description,topics  \n",
       "1   Deep Learning in:name,description,topics  \n",
       "2   Deep Learning in:name,description,topics  \n",
       "3   Deep Learning in:name,description,topics  \n",
       "4   Deep Learning in:name,description,topics  \n",
       "6                     Deep Learning tutorial  \n",
       "7                     Deep Learning tutorial  \n",
       "8                     Deep Learning tutorial  \n",
       "9                     Deep Learning tutorial  \n",
       "10                     Deep Learning awesome  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 11: Test the exact query you'll use in production\n",
    "def production_search_query(skill_name):\n",
    "    \"\"\"\n",
    "    The exact search pattern we'll use in Airflow\n",
    "    Optimized for finding learning resources\n",
    "    \"\"\"\n",
    "    \n",
    "    # Build a compound query\n",
    "    queries_to_try = [\n",
    "        f'{skill_name} in:name,description,topics',\n",
    "        f'{skill_name} tutorial',\n",
    "        f'{skill_name} awesome',  # \"Awesome\" lists are great resources\n",
    "    ]\n",
    "    \n",
    "    all_repos = []\n",
    "    \n",
    "    for query in queries_to_try:\n",
    "        print(f\"Query: {query}\")\n",
    "        results = search_repos(query, per_page=5)\n",
    "        if results:\n",
    "            df = repos_to_dataframe(results)\n",
    "            df['query_used'] = query\n",
    "            all_repos.append(df)\n",
    "    \n",
    "    if all_repos:\n",
    "        combined = pd.concat(all_repos, ignore_index=True)\n",
    "        # Remove duplicates (same repo from different queries)\n",
    "        combined = combined.drop_duplicates(subset=['full_name'])\n",
    "        return combined\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Test with a skill from your table\n",
    "test_skill = \"Deep Learning\"\n",
    "production_results = production_search_query(test_skill)\n",
    "\n",
    "print(f\"\\nFound {len(production_results)} unique repos for '{test_skill}'\")\n",
    "production_results[['full_name', 'stars', 'query_used']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f890e0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: awesome deep learning\n",
      "  ‚úì Found 5 repos\n",
      "Query: deep learning tutorial\n",
      "  ‚úì Found 5 repos\n",
      "Query: deep learning learn\n",
      "  ‚úì Found 5 repos\n",
      "Query: deep learning course\n",
      "  ‚úì Found 5 repos\n",
      "Query: deep learning examples\n",
      "  ‚úì Found 5 repos\n",
      "Query: deep learning projects\n",
      "  ‚úì Found 5 repos\n",
      "Query: deep learning interview\n",
      "  ‚úì Found 5 repos\n",
      "Query: deep learning practice\n",
      "  ‚úì Found 5 repos\n",
      "Query: deep learning in:name,description,topics NOT language:C++ NOT language:C\n",
      "  ‚úó No results\n",
      "\n",
      "Found 33 unique repos for 'deep learning'\n",
      "\n",
      "=== Top Learning Resources ===\n",
      "                                            full_name  stars query_type  \\\n",
      "1          ChristosChristofidis/awesome-deep-learning  26518    awesome   \n",
      "0   ashishpatel26/500-AI-Machine-learning-Deep-lea...  28692    awesome   \n",
      "12     floodsung/Deep-Learning-Papers-Reading-Roadmap  39365       deep   \n",
      "3               ujjwalkarn/Machine-Learning-Tutorials  17131    awesome   \n",
      "2                terryum/awesome-deep-learning-papers  26040    awesome   \n",
      "6                             yunjey/pytorch-tutorial  31912       deep   \n",
      "20                        NVIDIA/DeepLearningExamples  14552       deep   \n",
      "18                     Kulbear/deep-learning-coursera   7697       deep   \n",
      "9                            Mikoto10032/DeepLearning  16803       deep   \n",
      "15                    mrdbourke/pytorch-deep-learning  16225       deep   \n",
      "16                       lexfridman/mit-deep-learning  10382       deep   \n",
      "17            chiphuyen/stanford-tensorflow-tutorials  10374       deep   \n",
      "5   labmlai/annotated_deep_learning_paper_implemen...  64241       deep   \n",
      "35                                PaddlePaddle/Paddle  23385       deep   \n",
      "30                 amusi/Deep-Learning-Interview-Book   8593       deep   \n",
      "\n",
      "    learning_score  \n",
      "1           90.000  \n",
      "0           80.000  \n",
      "12          80.000  \n",
      "3           77.131  \n",
      "2           75.000  \n",
      "6           70.000  \n",
      "20          69.552  \n",
      "18          67.697  \n",
      "9           66.803  \n",
      "15          66.225  \n",
      "16          65.382  \n",
      "17          65.374  \n",
      "5           65.000  \n",
      "35          60.000  \n",
      "30          58.593  \n"
     ]
    }
   ],
   "source": [
    "# Cell 11 (Fixed): Production-ready search optimized for learning\n",
    "def production_search_query(skill_name):\n",
    "    \"\"\"\n",
    "    Optimized search for job seekers and learners\n",
    "    Prioritizes: tutorials, examples, awesome lists, interview prep\n",
    "    \"\"\"\n",
    "    \n",
    "    # Build queries that find LEARNING resources, not source code\n",
    "    queries_to_try = [\n",
    "        # Awesome lists (curated resources)\n",
    "        f'awesome {skill_name}',\n",
    "        \n",
    "        # Tutorial repositories\n",
    "        f'{skill_name} tutorial',\n",
    "        f'{skill_name} learn',\n",
    "        f'{skill_name} course',\n",
    "        \n",
    "        # Project examples\n",
    "        f'{skill_name} examples',\n",
    "        f'{skill_name} projects',\n",
    "        \n",
    "        # Interview preparation\n",
    "        f'{skill_name} interview',\n",
    "        f'{skill_name} practice',\n",
    "        \n",
    "        # General learning (with filters to avoid source code)\n",
    "        f'{skill_name} in:name,description,topics NOT language:C++ NOT language:C'\n",
    "    ]\n",
    "    \n",
    "    all_repos = []\n",
    "    \n",
    "    for query in queries_to_try:\n",
    "        print(f\"Query: {query}\")\n",
    "        try:\n",
    "            results = search_repos(query, per_page=5)\n",
    "            if results and results.get('items'):\n",
    "                df = repos_to_dataframe(results)\n",
    "                if not df.empty:  # Only add if we got results\n",
    "                    df['query_used'] = query\n",
    "                    df['query_type'] = query.split()[0]  # 'awesome', 'tutorial', etc.\n",
    "                    all_repos.append(df)\n",
    "                    print(f\"  ‚úì Found {len(df)} repos\")\n",
    "                else:\n",
    "                    print(f\"  ‚úó No results\")\n",
    "            else:\n",
    "                print(f\"  ‚úó No results\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó Error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if all_repos:\n",
    "        combined = pd.concat(all_repos, ignore_index=True)\n",
    "        # Remove duplicates\n",
    "        combined = combined.drop_duplicates(subset=['full_name'])\n",
    "        \n",
    "        # Score repos by learning value\n",
    "        combined = score_learning_value(combined)\n",
    "        \n",
    "        return combined.sort_values('learning_score', ascending=False)\n",
    "    else:\n",
    "        print(\"‚ö† No results found for any query\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def score_learning_value(df):\n",
    "    \"\"\"\n",
    "    Score repositories by how useful they are for learning/job prep\n",
    "    Higher score = better learning resource\n",
    "    \"\"\"\n",
    "    \n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    df = df.copy()\n",
    "    df['learning_score'] = 0.0\n",
    "    \n",
    "    # Bonus points for educational keywords in name/description\n",
    "    educational_keywords = [\n",
    "        'tutorial', 'learn', 'course', 'guide', 'beginner',\n",
    "        'awesome', 'examples', 'projects', 'interview', 'practice',\n",
    "        'bootcamp', 'workshop', 'introduction', 'roadmap'\n",
    "    ]\n",
    "    \n",
    "    for keyword in educational_keywords:\n",
    "        df.loc[df['full_name'].str.lower().str.contains(keyword, na=False), 'learning_score'] += 10\n",
    "        df.loc[df['description'].str.lower().str.contains(keyword, na=False), 'learning_score'] += 5\n",
    "    \n",
    "    # Penalize source code repos\n",
    "    source_keywords = ['implementation', 'core', 'framework', 'engine', 'library']\n",
    "    for keyword in source_keywords:\n",
    "        df.loc[df['full_name'].str.lower().str.contains(keyword, na=False), 'learning_score'] -= 5\n",
    "    \n",
    "    # Bonus for stars (popularity = likely quality)\n",
    "    df['learning_score'] += (df['stars'] / 1000).clip(0, 20)  # Max 20 bonus points\n",
    "    \n",
    "    # Calculate days_since_update if not already there\n",
    "    if 'days_since_update' not in df.columns:\n",
    "        from datetime import datetime, timezone\n",
    "        now = datetime.now(timezone.utc)\n",
    "        df['days_since_update'] = (now - df['updated_at']).dt.days\n",
    "    \n",
    "    # Bonus for recent updates (maintained)\n",
    "    df.loc[df['days_since_update'] < 180, 'learning_score'] += 10\n",
    "    df.loc[df['days_since_update'] < 90, 'learning_score'] += 5\n",
    "    \n",
    "    # Bonus for having good documentation indicators\n",
    "    df.loc[df['topics'].str.contains('tutorial|education|learning', case=False, na=False), 'learning_score'] += 15\n",
    "    \n",
    "    # Penalize if it's a language's core repo (e.g., 'python/cpython')\n",
    "    for idx, row in df.iterrows():\n",
    "        parts = row['full_name'].split('/')\n",
    "        if len(parts) == 2 and parts[0].lower() == parts[1].lower():\n",
    "            df.loc[idx, 'learning_score'] -= 20\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Test with deep learning\n",
    "test_skill = \"deep learning\"\n",
    "production_results = production_search_query(test_skill)\n",
    "\n",
    "if not production_results.empty:\n",
    "    print(f\"\\nFound {len(production_results)} unique repos for '{test_skill}'\")\n",
    "    print(\"\\n=== Top Learning Resources ===\")\n",
    "    print(production_results[['full_name', 'stars', 'query_type', 'learning_score']].head(15))\n",
    "else:\n",
    "    print(\"\\n‚ö† No results to display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6efb6962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73285aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PG_CONFIG = {\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"port\": int(os.getenv(\"DB_PORT\", 5432)),\n",
    "    \"database\": os.getenv(\"DB_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fa49199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\AppData\\Local\\Temp\\ipykernel_18804\\966503257.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  skills_df = pd.read_sql(\"SELECT * FROM role_skills_by_title\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4531 rows\n",
      "Columns: ['title_lc', 'skills_for_role']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_lc</th>\n",
       "      <th>skills_for_role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>software engineer - london</td>\n",
       "      <td>[\"agile\", \"aws\", \"clientside development\", \"co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>senior .net software engineer - biotech instru...</td>\n",
       "      <td>[\"aws\", \"biology\", \"c#\", \"chemistry\", \"cloud c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sr. software engineer (starshield) - top secre...</td>\n",
       "      <td>[\"adaptability\", \"aerospace\", \"algorithm devel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amd-xilinx csp embedded software engineer (fl/...</td>\n",
       "      <td>[\"arm\", \"bsd sockets\", \"c\", \"c++\", \"embedded s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>senior information assurance data analyst &amp; ne...</td>\n",
       "      <td>[\"8570.01m./dod 8140\", \"amazon cloud services\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title_lc  \\\n",
       "0                         software engineer - london   \n",
       "1  senior .net software engineer - biotech instru...   \n",
       "2  sr. software engineer (starshield) - top secre...   \n",
       "3  amd-xilinx csp embedded software engineer (fl/...   \n",
       "4  senior information assurance data analyst & ne...   \n",
       "\n",
       "                                     skills_for_role  \n",
       "0  [\"agile\", \"aws\", \"clientside development\", \"co...  \n",
       "1  [\"aws\", \"biology\", \"c#\", \"chemistry\", \"cloud c...  \n",
       "2  [\"adaptability\", \"aerospace\", \"algorithm devel...  \n",
       "3  [\"arm\", \"bsd sockets\", \"c\", \"c++\", \"embedded s...  \n",
       "4  [\"8570.01m./dod 8140\", \"amazon cloud services\"...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conn = psycopg2.connect(**PG_CONFIG)\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "skills_df = pd.read_sql(\"SELECT * FROM role_skills_by_title\", conn)\n",
    "\n",
    "print(f\"Loaded {len(skills_df)} rows\")\n",
    "print(f\"Columns: {skills_df.columns.tolist()}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(skills_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fb59293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique skills: 54004\n",
      "\n",
      "======================================================================\n",
      "TOP 25 MOST IN-DEMAND SKILLS (with categories)\n",
      "======================================================================\n",
      "\n",
      "             skill_name  frequency  category\n",
      "                 python       2153 technical\n",
      "                    sql       1510 technical\n",
      "                   java       1267 technical\n",
      "   software engineering       1160 technical\n",
      "          data analysis       1041 technical\n",
      "          communication        999 technical\n",
      "   software development        953 technical\n",
      "                    c++        915 technical\n",
      "                    aws        899 technical\n",
      "       machine learning        830 technical\n",
      "                  linux        731 technical\n",
      "                    git        721 technical\n",
      "       computer science        717 technical\n",
      "             javascript        717 technical\n",
      "     data visualization        715 technical\n",
      "                  agile        699 technical\n",
      "        problem solving        697 technical\n",
      "   communication skills        687 technical\n",
      "             kubernetes        647 technical\n",
      "                 docker        622 technical\n",
      "               teamwork        621 technical\n",
      "        cloud computing        559 technical\n",
      "          collaboration        558 technical\n",
      "         problemsolving        551 technical\n",
      "           data science        541 technical\n",
      "                 devops        522 technical\n",
      "                  azure        485 technical\n",
      "     project management        482 technical\n",
      "      agile development        472 technical\n",
      "           unit testing        468 technical\n",
      "                tableau        463 technical\n",
      "         data analytics        462 technical\n",
      "      analytical skills        455 technical\n",
      "      bachelor's degree        454 technical\n",
      "                   jira        442 technical\n",
      "                      r        440 technical\n",
      "                     c#        437 technical\n",
      "                  react        421 technical\n",
      "          data modeling        408 technical\n",
      "                  nosql        405 technical\n",
      "        software design        404 technical\n",
      "       data engineering        398 technical\n",
      "                testing        385 technical\n",
      "    attention to detail        382      soft\n",
      "                jenkins        381 technical\n",
      "             algorithms        379 technical\n",
      "             leadership        371 technical\n",
      "                  scrum        365 technical\n",
      "                  spark        364 technical\n",
      "        troubleshooting        359 technical\n",
      "              debugging        357 technical\n",
      "             statistics        347 technical\n",
      "        data management        346 technical\n",
      "       data warehousing        345 technical\n",
      "        data structures        344 technical\n",
      "          microservices        337 technical\n",
      "            data mining        334 technical\n",
      "             typescript        324 technical\n",
      "artificial intelligence        321 technical\n",
      "                  ci/cd        319 technical\n",
      "                    gcp        319 technical\n",
      "                  kafka        313 technical\n",
      "                   html        312 technical\n",
      "              mentoring        310 technical\n",
      "    distributed systems        309 technical\n",
      "                  c/c++        301 technical\n",
      "       software testing        299 technical\n",
      "                    css        297 technical\n",
      "  business intelligence        295 technical\n",
      "            engineering        291 technical\n",
      "  software architecture        290 technical\n",
      "                 hadoop        282 technical\n",
      "               power bi        281 technical\n",
      "                     go        279 technical\n",
      "                  scala        274 technical\n",
      " continuous integration        273 technical\n",
      "                      c        270 technical\n",
      "          documentation        269 technical\n",
      "                    etl        266 technical\n",
      "                angular        266 technical\n",
      "              reporting        262 technical\n",
      "       data integration        259 technical\n",
      "  problemsolving skills        259 technical\n",
      "               big data        252 technical\n",
      "            mathematics        252 technical\n",
      "         data pipelines        245 technical\n",
      "        data governance        245 technical\n",
      "   statistical analysis        239 technical\n",
      "      critical thinking        231 technical\n",
      "             confluence        228 technical\n",
      "                  excel        226 technical\n",
      "                node.js        225 technical\n",
      "                  mysql        222 technical\n",
      "        time management        220      soft\n",
      "                 oracle        219 technical\n",
      "              databases        219 technical\n",
      "                 design        219 technical\n",
      "             automation        213 technical\n",
      "           data quality        212 technical\n",
      "             postgresql        209 technical\n",
      "\n",
      "========================================\n",
      "Category Breakdown in Top 25:\n",
      "========================================\n",
      "category\n",
      "technical    98\n",
      "soft          2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell: Top 25 with categorization\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def extract_skills_frequency(df, skills_column='skills_for_role'):\n",
    "    \"\"\"\n",
    "    Extract all skills and count their frequency\n",
    "    \"\"\"\n",
    "    skill_counter = Counter()\n",
    "    \n",
    "    for skills_str in df[skills_column]:\n",
    "        if pd.isna(skills_str):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Parse JSON string to list\n",
    "            skills_list = json.loads(skills_str)\n",
    "            \n",
    "            # Update counter\n",
    "            skill_counter.update(skills_list)\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing: {skills_str[:50]}... - {e}\")\n",
    "            continue\n",
    "    \n",
    "    return skill_counter\n",
    "\n",
    "def categorize_skill(skill_name):\n",
    "    \"\"\"\n",
    "    Categorize a skill as technical, soft, or domain\n",
    "    \"\"\"\n",
    "    skill_lower = skill_name.lower()\n",
    "    \n",
    "    # Technical skills indicators\n",
    "    technical_indicators = ['python', 'sql', 'java', 'software engineering', 'data analysis', \n",
    "                   'software development', 'c++', 'aws', 'machine learning', 'linux', \n",
    "                   'git', 'computer science', 'javascript', 'data visualization', 'agile', \n",
    "                   'kubernetes', 'docker', 'cloud computing', 'data science', 'devops',\n",
    "                     'azure', 'project management', 'agile development', 'unit testing',\n",
    "                       'tableau', 'data analytics', 'jira', 'r', 'c#', 'react', 'data modeling', \n",
    "                       'nosql', 'software design', 'data engineering', 'testing', 'jenkins', \n",
    "                       'algorithms', 'scrum', 'spark', 'troubleshooting', 'debugging', \n",
    "                       'statistics', 'data management', 'data warehousing', 'data structures', \n",
    "                       'microservices', 'data mining', 'typescript', 'artificial intelligence', \n",
    "                       'ci/cd', 'gcp', 'kafka', 'html', 'distributed systems', 'c/c++', \n",
    "                       'software testing', 'css', 'business intelligence', 'engineering',\n",
    "                         'software architecture', 'hadoop', 'power bi', 'go', 'scala', 'continuous integration', \n",
    "                         'c', 'documentation', 'etl', 'angular', 'reporting', 'data integration', \n",
    "                         'big data', 'mathematics', 'data pipelines', 'data governance', 'statistical analysis', \n",
    "                         'confluence', 'excel', 'node.js', 'mysql', 'oracle', 'databases', 'design', 'automation', 'data quality', 'postgresql']\n",
    "    \n",
    "    # Soft skills indicators\n",
    "    soft_indicators = ['communication', 'problem solving', 'communication skills', \n",
    "                   'teamwork', 'collaboration', 'problemsolving', 'analytical skills',\n",
    "                     'attention to detail', 'leadership', 'mentoring', 'problemsolving skills',\n",
    "                       'critical thinking', 'time management']\n",
    "    \n",
    "    # Check for matches\n",
    "    if any(indicator in skill_lower for indicator in technical_indicators):\n",
    "        return 'technical'\n",
    "    elif any(indicator in skill_lower for indicator in soft_indicators):\n",
    "        return 'soft'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "# Extract and categorize\n",
    "skill_counter = extract_skills_frequency(skills_df)\n",
    "\n",
    "top_100_with_category = pd.DataFrame([\n",
    "    {\n",
    "        'skill_name': skill,\n",
    "        'frequency': count,\n",
    "        'category': categorize_skill(skill)\n",
    "    }\n",
    "    for skill, count in skill_counter.most_common(100)\n",
    "])\n",
    "\n",
    "print(f\"Total unique skills: {len(skill_counter)}\")\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TOP 25 MOST IN-DEMAND SKILLS (with categories)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "print(top_100_with_category.to_string(index=False))\n",
    "\n",
    "# Summary by category\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(\"Category Breakdown in Top 25:\")\n",
    "print(f\"{'='*40}\")\n",
    "print(top_100_with_category['category'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca93420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_skills = set()\n",
    "for i in range(len(skills_df)-1000):\n",
    "    row = json.loads(skills_df['skills_for_role'][i])\n",
    "    for skill in row:\n",
    "        all_skills.add(skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d7d9542",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUTUBE_API_KEY = os.getenv('YOUTUBE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b23610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71467ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3f48eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì API connection successful!\n",
      "\n",
      "Quota Info:\n",
      "- Daily quota: 10,000 units\n",
      "- Search cost: 100 units\n",
      "- Video stats cost: 1 unit\n",
      "- Estimated searches available: ~100 per day\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_quota_status():\n",
    "    \"\"\"\n",
    "    Test API connection and show quota info\n",
    "    \n",
    "    YouTube Data API quota:\n",
    "    - 10,000 units per day\n",
    "    - Search costs 100 units\n",
    "    - Video details cost 1 unit\n",
    "    - So you can do ~100 searches per day\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Simple test query (costs 100 units)\n",
    "        request = youtube.search().list(\n",
    "            part='snippet',\n",
    "            q='communication skills',\n",
    "            type='video',\n",
    "            maxResults=1\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        print(\"‚úì API connection successful!\")\n",
    "        print(\"\\nQuota Info:\")\n",
    "        print(\"- Daily quota: 10,000 units\")\n",
    "        print(\"- Search cost: 100 units\")\n",
    "        print(\"- Video stats cost: 1 unit\")\n",
    "        print(\"- Estimated searches available: ~100 per day\")\n",
    "        \n",
    "        return True\n",
    "    except HttpError as e:\n",
    "        print(f\"‚úó API Error: {e}\")\n",
    "        return False\n",
    "\n",
    "check_quota_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed51f00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching: communication skills tutorial\n",
      "   ‚úì Found 5 videos\n",
      "üîç Searching: how to improve communication\n",
      "   ‚úì Found 5 videos\n",
      "üîç Searching: communication training\n",
      "   ‚úì Found 5 videos\n",
      "üîç Searching: communication for professionals\n",
      "   ‚úì Found 5 videos\n",
      "üîç Searching: effective communication skills\n",
      "   ‚úì Found 5 videos\n",
      "\n",
      "================================================================================\n",
      "Found 11 unique videos across all strategies\n",
      "================================================================================\n",
      "\n",
      "                                                                                             title                    channel                      query_used\n",
      "                       Give me 8 minutes, and I&#39;ll improve your communication skills by 88%...                Jak Piggott  effective communication skills\n",
      "                       Listen to this if you want to level up your communication skills in 2025...                 Vinh Giang  effective communication skills\n",
      "Top 5 Tips to Improve Communication Skills | Soft Skills For Beginners | Soft Skills | Simplilearn                Simplilearn   communication skills tutorial\n",
      "   How to improve communication skills in the workplace fast | Professional communication training       The Wizard of Words  communication for professionals\n",
      "                                        The 3-2-1 Speaking Trick That Forces You To Stop Rambling!                 Vinh Giang          communication training\n",
      "            The science behind dramatically better conversations | Charles Duhigg | TEDxManchester                 TEDx Talks  effective communication skills\n",
      "                                                How To Improve Communication In Your Relationships The Mindset Mentor Podcast    how to improve communication\n",
      "                                Respond with Confidence: Tips to Improve Your Communication Skills           Jefferson Fisher  effective communication skills\n",
      "                                    Professional Communication Skills [BUSINESS COMMUNICATION PRO]            Adriana Girdler communication for professionals\n",
      "      It&#39;s Not Manipulation, It&#39;s Strategic Communication | Keisha Brewer | TEDxGeorgetown                 TEDx Talks communication for professionals\n",
      "               The Art of Effective Communication | Marcus Alexander Velazquez | TEDxWolcottSchool                 TEDx Talks  effective communication skills\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Test different search strategies for better results\n",
    "\n",
    "def explore_search_strategies(skill_name):\n",
    "    \"\"\"\n",
    "    Try different search queries to find best learning content\n",
    "    \"\"\"\n",
    "    \n",
    "    search_strategies = [\n",
    "        f'{skill_name} skills tutorial',\n",
    "        f'how to improve {skill_name}',\n",
    "        f'{skill_name} training',\n",
    "        f'{skill_name} for professionals',\n",
    "        f'effective {skill_name} skills',\n",
    "    ]\n",
    "    \n",
    "    all_videos = []\n",
    "    \n",
    "    for query in search_strategies:\n",
    "        print(f\"üîç Searching: {query}\")\n",
    "        \n",
    "        try:\n",
    "            search_request = youtube.search().list(\n",
    "                part='snippet',\n",
    "                q=query,\n",
    "                type='video',\n",
    "                order='relevance',\n",
    "                maxResults=5,\n",
    "                videoDuration='medium',\n",
    "                relevanceLanguage='en'\n",
    "            )\n",
    "            \n",
    "            response = search_request.execute()\n",
    "            \n",
    "            if 'items' in response:\n",
    "                print(f\"   ‚úì Found {len(response['items'])} videos\")\n",
    "                \n",
    "                for item in response['items']:\n",
    "                    all_videos.append({\n",
    "                        'video_id': item['id']['videoId'],\n",
    "                        'title': item['snippet']['title'],\n",
    "                        'channel': item['snippet']['channelTitle'],\n",
    "                        'url': f\"https://www.youtube.com/watch?v={item['id']['videoId']}\",\n",
    "                        'query_used': query\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"   ‚úó No results\")\n",
    "                \n",
    "        except HttpError as e:\n",
    "            print(f\"   ‚úó Error: {e}\")\n",
    "    \n",
    "    # Remove duplicates by video_id\n",
    "    unique_videos = {v['video_id']: v for v in all_videos}.values()\n",
    "    \n",
    "    return pd.DataFrame(unique_videos)\n",
    "\n",
    "# Test different strategies\n",
    "strategy_results = explore_search_strategies(\"communication\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Found {len(strategy_results)} unique videos across all strategies\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "print(strategy_results[['title', 'channel', 'query_used']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854ad245",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()\n",
    "\n",
    "# SQL to create tables\n",
    "create_tables_sql = \"\"\"\n",
    "-- 1. Learning resources table (unified for GitHub and YouTube)\n",
    "CREATE TABLE IF NOT EXISTS learning_resources (\n",
    "    resource_id SERIAL PRIMARY KEY,\n",
    "    resource_url TEXT UNIQUE NOT NULL,  -- URL is the unique identifier\n",
    "    resource_type VARCHAR(50) NOT NULL,  -- 'github_repo' or 'youtube_video'\n",
    "    title TEXT,\n",
    "    description TEXT,\n",
    "    platform VARCHAR(100),  -- 'github' or 'youtube'\n",
    "    \n",
    "    -- Metadata (varies by type)\n",
    "    metadata JSONB,  -- Flexible storage for type-specific fields\n",
    "    \n",
    "    -- Common metrics\n",
    "    popularity_score INTEGER DEFAULT 0,  -- stars for GitHub, views for YouTube\n",
    "    engagement_score INTEGER DEFAULT 0,  -- forks for GitHub, likes for YouTube\n",
    "    \n",
    "    -- Timestamps\n",
    "    published_at TIMESTAMP,\n",
    "    fetched_at TIMESTAMP DEFAULT NOW(),\n",
    "    last_updated TIMESTAMP DEFAULT NOW()\n",
    ");\n",
    "\n",
    "-- 2. Skills table\n",
    "CREATE TABLE IF NOT EXISTS skills (\n",
    "    skill_name VARCHAR(255) PRIMARY KEY,\n",
    "    skill_type VARCHAR(50),  -- 'technical', 'soft', 'domain'\n",
    "    frequency INTEGER DEFAULT 0,  -- How often it appears in job postings\n",
    "    fetch_priority INTEGER DEFAULT 1,\n",
    "    is_active BOOLEAN DEFAULT TRUE,\n",
    "    first_seen TIMESTAMP DEFAULT NOW(),\n",
    "    last_fetched TIMESTAMP\n",
    ");\n",
    "\n",
    "-- 3. Many-to-many relationship\n",
    "CREATE TABLE IF NOT EXISTS resource_skills (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    resource_id INTEGER REFERENCES learning_resources(resource_id) ON DELETE CASCADE,\n",
    "    skill_name VARCHAR(255) REFERENCES skills(skill_name) ON DELETE CASCADE,\n",
    "    relevance_score DECIMAL(5,2) DEFAULT 0.0,  -- 0-100: how relevant is this resource to this skill\n",
    "    detected_from VARCHAR(255),  -- Which search query found this match\n",
    "    learning_score DECIMAL(5,2) DEFAULT 0.0,  -- 0-100: educational value score\n",
    "    detected_at TIMESTAMP DEFAULT NOW(),\n",
    "    UNIQUE(resource_id, skill_name)\n",
    ");\n",
    "\n",
    "-- 4. Indexes for performance\n",
    "CREATE INDEX IF NOT EXISTS idx_resources_type ON learning_resources(resource_type);\n",
    "CREATE INDEX IF NOT EXISTS idx_resources_popularity ON learning_resources(popularity_score DESC);\n",
    "CREATE INDEX IF NOT EXISTS idx_resources_url ON learning_resources(resource_url);\n",
    "CREATE INDEX IF NOT EXISTS idx_skills_type ON skills(skill_type);\n",
    "CREATE INDEX IF NOT EXISTS idx_skills_frequency ON skills(frequency DESC);\n",
    "CREATE INDEX IF NOT EXISTS idx_resource_skills_skill ON resource_skills(skill_name);\n",
    "CREATE INDEX IF NOT EXISTS idx_resource_skills_resource ON resource_skills(resource_id);\n",
    "CREATE INDEX IF NOT EXISTS idx_resource_skills_relevance ON resource_skills(relevance_score DESC);\n",
    "CREATE INDEX IF NOT EXISTS idx_resource_skills_learning ON resource_skills(learning_score DESC);\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    cursor.execute(create_tables_sql)\n",
    "    conn.commit()\n",
    "    print(\"‚úì Tables created successfully!\")\n",
    "    \n",
    "    # Verify tables\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT table_name \n",
    "        FROM information_schema.tables \n",
    "        WHERE table_schema = 'public' \n",
    "        AND table_name IN ('learning_resources', 'skills', 'resource_skills')\n",
    "    \"\"\")\n",
    "    \n",
    "    tables = cursor.fetchall()\n",
    "    print(f\"‚úì Verified tables: {[t[0] for t in tables]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error creating tables: {e}\")\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0eecdc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Inserted/Updated 100 skills\n",
      "\n",
      "Skills by category:\n",
      "  technical: 98\n",
      "  soft: 2\n"
     ]
    }
   ],
   "source": [
    "def insert_skills_to_db(skills_df):\n",
    "    \"\"\"\n",
    "    Insert skills from your top_100_with_category DataFrame\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    inserted = 0\n",
    "    skipped = 0\n",
    "    \n",
    "    for _, row in skills_df.iterrows():\n",
    "        try:\n",
    "            priority = min(10, max(1, int(row['frequency'] / 100)))\n",
    "            \n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO skills (skill_name, skill_type, frequency, fetch_priority)\n",
    "                VALUES (%s, %s, %s, %s)\n",
    "                ON CONFLICT (skill_name) DO UPDATE\n",
    "                SET frequency = EXCLUDED.frequency,\n",
    "                    skill_type = EXCLUDED.skill_type,\n",
    "                    fetch_priority = EXCLUDED.fetch_priority\n",
    "            \"\"\", (\n",
    "                row['skill_name'],\n",
    "                row['category'],\n",
    "                row['frequency'],\n",
    "                priority\n",
    "            ))\n",
    "            inserted += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting {row['skill_name']}: {e}\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"‚úì Inserted/Updated {inserted} skills\")\n",
    "    if skipped > 0:\n",
    "        print(f\"‚ö† Skipped {skipped} skills\")\n",
    "    \n",
    "    return inserted\n",
    "\n",
    "# Insert your skills\n",
    "total_skills = insert_skills_to_db(top_100_with_category)\n",
    "\n",
    "# Show breakdown\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT skill_type, COUNT(*) \n",
    "    FROM skills \n",
    "    GROUP BY skill_type\n",
    "    ORDER BY COUNT(*) DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nSkills by category:\")\n",
    "for row in cursor.fetchall():\n",
    "    print(f\"  {row[0]}: {row[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9bbbcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_name</th>\n",
       "      <th>frequency</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>2153</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql</td>\n",
       "      <td>1510</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>java</td>\n",
       "      <td>1267</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>software engineering</td>\n",
       "      <td>1160</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>1041</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>databases</td>\n",
       "      <td>219</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>design</td>\n",
       "      <td>219</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>automation</td>\n",
       "      <td>213</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>data quality</td>\n",
       "      <td>212</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>postgresql</td>\n",
       "      <td>209</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              skill_name  frequency   category\n",
       "0                 python       2153  technical\n",
       "1                    sql       1510  technical\n",
       "2                   java       1267  technical\n",
       "3   software engineering       1160  technical\n",
       "4          data analysis       1041  technical\n",
       "..                   ...        ...        ...\n",
       "95             databases        219  technical\n",
       "96                design        219  technical\n",
       "97            automation        213  technical\n",
       "98          data quality        212  technical\n",
       "99            postgresql        209  technical\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100_with_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4ce97f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Updated insert_youtube_resource with HTML decoding\n",
      "‚úì Helper functions loaded\n"
     ]
    }
   ],
   "source": [
    "import html\n",
    "def calculate_learning_score_github(repo):\n",
    "    \"\"\"Calculate learning value score for GitHub repo (0-100)\"\"\"\n",
    "    score = 0.0\n",
    "    \n",
    "    full_name_lower = repo['full_name'].lower()\n",
    "    desc_lower = repo.get('description', '').lower()\n",
    "    \n",
    "    # Educational keywords\n",
    "    educational_keywords = [\n",
    "        'tutorial', 'learn', 'course', 'guide', 'beginner',\n",
    "        'awesome', 'examples', 'projects', 'practice', 'introduction'\n",
    "    ]\n",
    "    \n",
    "    for keyword in educational_keywords:\n",
    "        if keyword in full_name_lower:\n",
    "            score += 10\n",
    "        if keyword in desc_lower:\n",
    "            score += 5\n",
    "    \n",
    "    # Awesome lists get big bonus\n",
    "    if 'awesome' in full_name_lower:\n",
    "        score += 20\n",
    "    \n",
    "    # Stars bonus (capped)\n",
    "    score += min(repo['stargazers_count'] / 100, 20)\n",
    "    \n",
    "    # Recent updates bonus\n",
    "    from datetime import datetime, timezone\n",
    "    try:\n",
    "        updated_at = datetime.strptime(repo['updated_at'], '%Y-%m-%dT%H:%M:%SZ').replace(tzinfo=timezone.utc)\n",
    "        days_since_update = (datetime.now(timezone.utc) - updated_at).days\n",
    "        if days_since_update < 180:\n",
    "            score += 10\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return min(score, 100.0)\n",
    "\n",
    "def calculate_relevance_score(repo, skill):\n",
    "    \"\"\"Calculate how relevant a repo is to a specific skill (0-100)\"\"\"\n",
    "    score = 0.0\n",
    "    skill_lower = skill.lower()\n",
    "    \n",
    "    if skill_lower in repo['full_name'].lower():\n",
    "        score += 40\n",
    "    if skill_lower in repo.get('description', '').lower():\n",
    "        score += 20\n",
    "    if skill_lower in ' '.join(repo.get('topics', [])).lower():\n",
    "        score += 30\n",
    "    if skill_lower == repo.get('language', '').lower():\n",
    "        score += 10\n",
    "    \n",
    "    return min(score, 100.0)\n",
    "\n",
    "def calculate_learning_score_youtube(video):\n",
    "    \"\"\"Calculate learning value score for YouTube video (0-100)\"\"\"\n",
    "    score = 0.0\n",
    "    \n",
    "    # View count (popularity)\n",
    "    score += min(video['view_count'] / 10000, 30)\n",
    "    \n",
    "    # Engagement rate\n",
    "    if video['view_count'] > 0:\n",
    "        engagement_rate = ((video['like_count'] + video['comment_count']) / video['view_count']) * 100\n",
    "        score += min(engagement_rate * 10, 30)\n",
    "    \n",
    "    # Educational keywords\n",
    "    title_desc = (video['title'] + ' ' + video.get('description', '')).lower()\n",
    "    if any(word in title_desc for word in ['tutorial', 'guide', 'learn', 'training', 'course']):\n",
    "        score += 20\n",
    "    \n",
    "    # TEDx or professional channels bonus\n",
    "    if 'tedx' in video['channel_name'].lower() or 'professional' in video['channel_name'].lower():\n",
    "        score += 20\n",
    "    \n",
    "    return min(score, 100.0)\n",
    "\n",
    "def insert_github_resource(repo_data, skill_name, query_used):\n",
    "    \"\"\"\n",
    "    Insert a GitHub repo into learning_resources and link to skill\n",
    "    Returns resource_id if successful, None otherwise\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        # Calculate scores\n",
    "        learning_score = calculate_learning_score_github(repo_data)\n",
    "        relevance_score = calculate_relevance_score(repo_data, skill_name)\n",
    "        \n",
    "        # Prepare metadata\n",
    "        metadata = {\n",
    "            'owner': repo_data['owner']['login'],\n",
    "            'repo_name': repo_data['name'],\n",
    "            'language': repo_data.get('language', ''),\n",
    "            'topics': repo_data.get('topics', []),\n",
    "            'forks': repo_data['forks_count'],\n",
    "            'watchers': repo_data['watchers_count'],\n",
    "            'open_issues': repo_data['open_issues_count'],\n",
    "            'created_at': repo_data['created_at'],\n",
    "            'updated_at': repo_data['updated_at']\n",
    "        }\n",
    "        \n",
    "        # Insert resource (URL is unique - will update if exists)\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO learning_resources \n",
    "            (resource_url, resource_type, title, description, platform, \n",
    "             popularity_score, engagement_score, metadata, published_at)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (resource_url) \n",
    "            DO UPDATE SET\n",
    "                popularity_score = EXCLUDED.popularity_score,\n",
    "                engagement_score = EXCLUDED.engagement_score,\n",
    "                last_updated = NOW()\n",
    "            RETURNING resource_id\n",
    "        \"\"\", (\n",
    "            repo_data['html_url'],\n",
    "            'github_repo',\n",
    "            repo_data['full_name'],\n",
    "            repo_data.get('description', '')[:500] if repo_data.get('description') else '',\n",
    "            'github',\n",
    "            repo_data['stargazers_count'],\n",
    "            repo_data['forks_count'],\n",
    "            json.dumps(metadata),\n",
    "            repo_data['created_at']\n",
    "        ))\n",
    "        \n",
    "        resource_id = cursor.fetchone()[0]\n",
    "        \n",
    "        # Link to skill\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO resource_skills \n",
    "            (resource_id, skill_name, relevance_score, learning_score, detected_from)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (resource_id, skill_name) \n",
    "            DO UPDATE SET\n",
    "                relevance_score = EXCLUDED.relevance_score,\n",
    "                learning_score = EXCLUDED.learning_score\n",
    "        \"\"\", (\n",
    "            resource_id,\n",
    "            skill_name,\n",
    "            relevance_score,\n",
    "            learning_score,\n",
    "            query_used\n",
    "        ))\n",
    "        \n",
    "        conn.commit()\n",
    "        return resource_id\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Error: {e}\")\n",
    "        conn.rollback()\n",
    "        return None\n",
    "\n",
    "# Update the insert_youtube_resource function\n",
    "def insert_youtube_resource(video_data, skill_name, query_used):\n",
    "    \"\"\"\n",
    "    Insert a YouTube video into learning_resources and link to skill\n",
    "    Returns resource_id if successful, None otherwise\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        # Calculate scores\n",
    "        learning_score = calculate_learning_score_youtube(video_data)\n",
    "        relevance_score = 50.0  # Default for YouTube (all results are relevant)\n",
    "        \n",
    "        # DECODE HTML ENTITIES in title and description\n",
    "        decoded_title = html.unescape(video_data['title'])\n",
    "        decoded_description = html.unescape(video_data.get('description', ''))\n",
    "        \n",
    "        # Prepare metadata\n",
    "        metadata = {\n",
    "            'video_id': video_data['video_id'],\n",
    "            'channel': video_data['channel_name'],\n",
    "            'duration': video_data['duration'],\n",
    "            'likes': video_data['like_count'],\n",
    "            'comments': video_data['comment_count']\n",
    "        }\n",
    "        \n",
    "        # Insert resource (URL is unique - will update if exists)\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO learning_resources \n",
    "            (resource_url, resource_type, title, description, platform, \n",
    "             popularity_score, engagement_score, metadata, published_at)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (resource_url) \n",
    "            DO UPDATE SET\n",
    "                popularity_score = EXCLUDED.popularity_score,\n",
    "                engagement_score = EXCLUDED.engagement_score,\n",
    "                title = EXCLUDED.title,\n",
    "                description = EXCLUDED.description,\n",
    "                last_updated = NOW()\n",
    "            RETURNING resource_id\n",
    "        \"\"\", (\n",
    "            video_data['url'],\n",
    "            'youtube_video',\n",
    "            decoded_title,  # ‚Üê DECODED\n",
    "            decoded_description[:500] if decoded_description else '',  # ‚Üê DECODED\n",
    "            'youtube',\n",
    "            video_data['view_count'],\n",
    "            video_data['like_count'],\n",
    "            json.dumps(metadata),\n",
    "            video_data['published_at']\n",
    "        ))\n",
    "        \n",
    "        resource_id = cursor.fetchone()[0]\n",
    "        \n",
    "        # Link to skill\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO resource_skills \n",
    "            (resource_id, skill_name, relevance_score, learning_score, detected_from)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (resource_id, skill_name) \n",
    "            DO UPDATE SET\n",
    "                relevance_score = EXCLUDED.relevance_score,\n",
    "                learning_score = EXCLUDED.learning_score\n",
    "        \"\"\", (\n",
    "            resource_id,\n",
    "            skill_name,\n",
    "            relevance_score,\n",
    "            learning_score,\n",
    "            query_used\n",
    "        ))\n",
    "        \n",
    "        conn.commit()\n",
    "        return resource_id\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Error: {e}\")\n",
    "        conn.rollback()\n",
    "        return None\n",
    "\n",
    "print(\"‚úì Updated insert_youtube_resource with HTML decoding\")\n",
    "print(\"‚úì Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761108db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
    "headers = {\n",
    "    'Authorization': f'token {GITHUB_TOKEN}',\n",
    "    'Accept': 'application/vnd.github.v3+json'\n",
    "}\n",
    "\n",
    "# Get technical skills from your DataFrame\n",
    "technical_skills = top_100_with_category[\n",
    "    top_100_with_category['category'] == 'technical'\n",
    "]['skill_name'].tolist()\n",
    "\n",
    "print(f\"Fetching GitHub repos for {len(technical_skills)} technical skills...\\n\")\n",
    "\n",
    "total_inserted = 0\n",
    "total_resources = 0\n",
    "\n",
    "for i, skill in enumerate(technical_skills, 1):\n",
    "    print(f\"[{i}/{len(technical_skills)}] {skill}\")\n",
    "    \n",
    "    # Use smart search queries\n",
    "    queries = [\n",
    "        f'awesome {skill}',\n",
    "        f'{skill} tutorial',\n",
    "        f'{skill} examples',\n",
    "    ]\n",
    "    \n",
    "    skill_resources = 0\n",
    "    seen_repos = set()\n",
    "    \n",
    "    for query in queries:\n",
    "        try:\n",
    "            url = f'https://api.github.com/search/repositories?q={query}&sort=stars&order=desc&per_page=5'\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            results = response.json()\n",
    "            \n",
    "            if 'items' in results:\n",
    "                for repo in results['items']:\n",
    "                    # Skip duplicates\n",
    "                    if repo['html_url'] in seen_repos:\n",
    "                        continue\n",
    "                    seen_repos.add(repo['html_url'])\n",
    "                    \n",
    "                    resource_id = insert_github_resource(repo, skill, query)\n",
    "                    if resource_id:\n",
    "                        skill_resources += 1\n",
    "                        total_resources += 1\n",
    "            \n",
    "            time.sleep(0.5)  # Rate limiting\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó Query '{query}' failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if skill_resources > 0:\n",
    "        print(f\"  ‚úì Added {skill_resources} repos\")\n",
    "        total_inserted += 1\n",
    "    else:\n",
    "        print(f\"  ‚ö† No repos added\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úì Skills processed: {total_inserted}/{len(technical_skills)}\")\n",
    "print(f\"‚úì Total GitHub repos inserted: {total_resources}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74c3dbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills that already have GitHub repos: 71\n",
      "Remaining skills to fetch: 27\n",
      "\n",
      "Remaining skills: ['engineering', 'software architecture', 'scala', 'continuous integration', 'c', 'documentation', 'etl', 'angular', 'reporting', 'data integration'] ...\n"
     ]
    }
   ],
   "source": [
    "# Check what skills already have resources\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT DISTINCT s.skill_name\n",
    "    FROM skills s\n",
    "    LEFT JOIN resource_skills rs ON s.skill_name = rs.skill_name\n",
    "    LEFT JOIN learning_resources lr ON rs.resource_id = lr.resource_id\n",
    "    WHERE s.skill_type = 'technical' \n",
    "    AND lr.resource_type = 'github_repo'\n",
    "\"\"\")\n",
    "\n",
    "skills_with_repos = {row[0] for row in cursor.fetchall()}\n",
    "\n",
    "print(f\"Skills that already have GitHub repos: {len(skills_with_repos)}\")\n",
    "\n",
    "# Get remaining skills to fetch\n",
    "technical_skills = top_100_with_category[\n",
    "    top_100_with_category['category'] == 'technical'\n",
    "]['skill_name'].tolist()\n",
    "\n",
    "remaining_skills = [s for s in technical_skills if s not in skills_with_repos]\n",
    "\n",
    "print(f\"Remaining skills to fetch: {len(remaining_skills)}\")\n",
    "print(\"\\nRemaining skills:\", remaining_skills[:10], \"...\" if len(remaining_skills) > 10 else \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "558c12a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 30 search requests available\n",
      "Rate limit resets at: 2025-11-11 11:55:00\n",
      "\n",
      "[1/27] engineering\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 6 repos\n",
      "[2/27] software architecture\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 1 repos\n",
      "[3/27] scala\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 9 repos\n",
      "[4/27] continuous integration\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 6 repos\n",
      "[5/27] c\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 4 repos\n",
      "[6/27] documentation\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 6 repos\n",
      "[7/27] etl\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 6 repos\n",
      "[8/27] angular\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 8 repos\n",
      "[9/27] reporting\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 5 repos\n",
      "[10/27] data integration\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 5 repos\n",
      "[11/27] problemsolving skills\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 1 repos\n",
      "[12/27] big data\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 4 repos\n",
      "[13/27] mathematics\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 8 repos\n",
      "[14/27] data pipelines\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 6 repos\n",
      "[15/27] data governance\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 1 repos\n",
      "[16/27] statistical analysis\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 4 repos\n",
      "[17/27] critical thinking\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 2 repos\n",
      "[18/27] confluence\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 4 repos\n",
      "[19/27] excel\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 4 repos\n",
      "[20/27] node.js\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 5 repos\n",
      "[21/27] mysql\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 5 repos\n",
      "[22/27] oracle\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 3 repos\n",
      "[23/27] databases\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 7 repos\n",
      "[24/27] design\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 7 repos\n",
      "[25/27] automation\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 6 repos\n",
      "[26/27] data quality\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 4 repos\n",
      "[27/27] postgresql\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úó Error: 'NoneType' object has no attribute 'lower'\n",
      "  ‚úì Added 6 repos\n",
      "\n",
      "============================================================\n",
      "‚úì Skills processed: 27/98\n",
      "‚úì Total GitHub repos inserted: 133\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    'Authorization': f'token {GITHUB_TOKEN}',\n",
    "    'Accept': 'application/vnd.github.v3+json'\n",
    "}\n",
    "\n",
    "def check_rate_limit():\n",
    "    \"\"\"Check remaining rate limit\"\"\"\n",
    "    response = requests.get('https://api.github.com/rate_limit', headers=headers)\n",
    "    data = response.json()\n",
    "    search_limit = data['resources']['search']\n",
    "    return search_limit['remaining'], search_limit['reset']\n",
    "\n",
    "def wait_for_rate_limit_reset():\n",
    "    \"\"\"Wait until rate limit resets\"\"\"\n",
    "    remaining, reset_time = check_rate_limit()\n",
    "    \n",
    "    if remaining == 0:\n",
    "        wait_seconds = reset_time - time.time() + 5  # Add 5 second buffer\n",
    "        print(f\"\\n‚è≥ Rate limit reached. Waiting {wait_seconds/60:.1f} minutes...\")\n",
    "        time.sleep(wait_seconds)\n",
    "        print(\"‚úì Rate limit reset. Continuing...\")\n",
    "    \n",
    "    return remaining\n",
    "\n",
    "# Check initial rate limit\n",
    "remaining, reset_time = check_rate_limit()\n",
    "print(f\"Starting with {remaining} search requests available\")\n",
    "print(f\"Rate limit resets at: {datetime.fromtimestamp(reset_time)}\\n\")\n",
    "\n",
    "total_inserted = 0\n",
    "total_resources = 0\n",
    "\n",
    "for i, skill in enumerate(remaining_skills, 1):\n",
    "    print(f\"[{i}/{len(remaining_skills)}] {skill}\")\n",
    "    \n",
    "    # Check rate limit before processing skill\n",
    "    remaining = wait_for_rate_limit_reset()\n",
    "    \n",
    "    queries = [\n",
    "        f'awesome {skill}',\n",
    "        f'{skill} tutorial',\n",
    "    ]\n",
    "    \n",
    "    skill_resources = 0\n",
    "    seen_repos = set()\n",
    "    \n",
    "    for query in queries:\n",
    "        # Check rate limit before each query\n",
    "        if remaining <= 2:  # Leave buffer\n",
    "            remaining = wait_for_rate_limit_reset()\n",
    "        \n",
    "        try:\n",
    "            url = f'https://api.github.com/search/repositories?q={query}&sort=stars&order=desc&per_page=5'\n",
    "            response = requests.get(url, headers=headers)\n",
    "            \n",
    "            # Handle rate limiting\n",
    "            if response.status_code == 403:\n",
    "                print(f\"  ‚è≥ Rate limit hit, waiting...\")\n",
    "                wait_for_rate_limit_reset()\n",
    "                # Retry the request\n",
    "                response = requests.get(url, headers=headers)\n",
    "            \n",
    "            response.raise_for_status()\n",
    "            results = response.json()\n",
    "            \n",
    "            if 'items' in results:\n",
    "                for repo in results['items']:\n",
    "                    if repo['html_url'] in seen_repos:\n",
    "                        continue\n",
    "                    seen_repos.add(repo['html_url'])\n",
    "                    \n",
    "                    resource_id = insert_github_resource(repo, skill, query)\n",
    "                    if resource_id:\n",
    "                        skill_resources += 1\n",
    "                        total_resources += 1\n",
    "            \n",
    "            # Rate limiting: 30 requests per minute = 2 seconds between requests\n",
    "            time.sleep(2.5)\n",
    "            remaining -= 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó Query '{query}' failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if skill_resources > 0:\n",
    "        print(f\"  ‚úì Added {skill_resources} repos\")\n",
    "        total_inserted += 1\n",
    "    else:\n",
    "        print(f\"  ‚ö† No repos added\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úì Skills processed: {total_inserted}/{len(technical_skills)}\")\n",
    "print(f\"‚úì Total GitHub repos inserted: {total_resources}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15e65292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Inserted: communication\n",
      "‚úì Inserted: teamwork\n",
      "‚úì Inserted: presentation skills\n",
      "‚úì Inserted: problem solving\n",
      "‚úì Inserted: critical thinking\n",
      "‚úì Inserted: leadership\n",
      "\n",
      "‚úì Successfully inserted 6/6 skills\n",
      "\n",
      "Verified 6 skills in database:\n",
      "  - communication\n",
      "  - critical thinking\n",
      "  - leadership\n",
      "  - presentation skills\n",
      "  - problem solving\n",
      "  - teamwork\n"
     ]
    }
   ],
   "source": [
    "# Cell: Insert the 6 manually identified soft skills\n",
    "\n",
    "manual_soft_skills = [\n",
    "    'communication',\n",
    "    'teamwork', \n",
    "    'presentation skills',\n",
    "    'problem solving',\n",
    "    'critical thinking',\n",
    "    'leadership'\n",
    "]\n",
    "\n",
    "inserted = 0\n",
    "\n",
    "for skill in manual_soft_skills:\n",
    "    try:\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO skills (skill_name, skill_type, frequency, fetch_priority, is_active)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (skill_name) DO NOTHING\n",
    "        \"\"\", (\n",
    "            skill,\n",
    "            'soft',      # All are soft skills\n",
    "            120,           # Frequency 0 (not in top 100, but still important)\n",
    "            5,           # Medium priority\n",
    "            True\n",
    "        ))\n",
    "        inserted += 1\n",
    "        print(f\"‚úì Inserted: {skill}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error inserting '{skill}': {e}\")\n",
    "\n",
    "conn.commit()\n",
    "print(f\"\\n‚úì Successfully inserted {inserted}/6 skills\")\n",
    "\n",
    "# Verify they're in the database\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT skill_name \n",
    "    FROM skills \n",
    "    WHERE skill_name = ANY(%s)\n",
    "    ORDER BY skill_name\n",
    "\"\"\", (manual_soft_skills,))\n",
    "\n",
    "found = cursor.fetchall()\n",
    "print(f\"\\nVerified {len(found)} skills in database:\")\n",
    "for row in found:\n",
    "    print(f\"  - {row[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f3cbb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching YouTube videos for 8 soft skills...\n",
      "\n",
      "[1/8] attention to detail\n",
      "  ‚úì Added 5 videos\n",
      "[2/8] time management\n",
      "  ‚úì Added 6 videos\n",
      "[3/8] communication\n",
      "  ‚úì Added 7 videos\n",
      "[4/8] teamwork\n",
      "  ‚úì Added 7 videos\n",
      "[5/8] presentation skills\n",
      "  ‚úì Added 7 videos\n",
      "[6/8] problem solving\n",
      "  ‚úì Added 4 videos\n",
      "[7/8] critical thinking\n",
      "  ‚úì Added 4 videos\n",
      "[8/8] leadership\n",
      "  ‚úì Added 5 videos\n",
      "\n",
      "============================================================\n",
      "‚úì Skills processed: 8/8\n",
      "‚úì Total YouTube videos inserted: 45\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)\n",
    "\n",
    "# Get soft skills from your DataFrame\n",
    "soft_skills = top_100_with_category[\n",
    "    top_100_with_category['category'] == 'soft'\n",
    "]['skill_name'].tolist()\n",
    "soft_skills.extend(manual_soft_skills)\n",
    "print(f\"Fetching YouTube videos for {len(soft_skills)} soft skills...\\n\")\n",
    "\n",
    "total_inserted = 0\n",
    "total_resources = 0\n",
    "\n",
    "for i, skill in enumerate(soft_skills, 1):\n",
    "    print(f\"[{i}/{len(soft_skills)}] {skill}\")\n",
    "    \n",
    "    queries = [\n",
    "        f'{skill} skills tutorial',\n",
    "        f'how to improve {skill}',\n",
    "        f'effective {skill} skills',\n",
    "    ]\n",
    "    \n",
    "    skill_resources = 0\n",
    "    seen_videos = set()\n",
    "    \n",
    "    for query in queries:\n",
    "        try:\n",
    "            # Search\n",
    "            search_request = youtube.search().list(\n",
    "                part='snippet',\n",
    "                q=query,\n",
    "                type='video',\n",
    "                order='relevance',\n",
    "                maxResults=3,\n",
    "                videoDuration='medium',\n",
    "                relevanceLanguage='en'\n",
    "            )\n",
    "            \n",
    "            search_response = search_request.execute()\n",
    "            \n",
    "            if 'items' not in search_response:\n",
    "                continue\n",
    "            \n",
    "            video_ids = [item['id']['videoId'] for item in search_response['items']]\n",
    "            \n",
    "            # Get statistics\n",
    "            stats_request = youtube.videos().list(\n",
    "                part='statistics,contentDetails',\n",
    "                id=','.join(video_ids)\n",
    "            )\n",
    "            \n",
    "            stats_response = stats_request.execute()\n",
    "            \n",
    "            # Process videos\n",
    "            for search_item, stats_item in zip(search_response['items'], stats_response['items']):\n",
    "                video_id = search_item['id']['videoId']\n",
    "                \n",
    "                # Skip duplicates\n",
    "                if video_id in seen_videos:\n",
    "                    continue\n",
    "                seen_videos.add(video_id)\n",
    "                \n",
    "                video_data = {\n",
    "                    'video_id': video_id,\n",
    "                    'title': search_item['snippet']['title'],\n",
    "                    'channel_name': search_item['snippet']['channelTitle'],\n",
    "                    'description': search_item['snippet']['description'],\n",
    "                    'published_at': search_item['snippet']['publishedAt'],\n",
    "                    'url': f\"https://www.youtube.com/watch?v={video_id}\",\n",
    "                    'view_count': int(stats_item['statistics'].get('viewCount', 0)),\n",
    "                    'like_count': int(stats_item['statistics'].get('likeCount', 0)),\n",
    "                    'comment_count': int(stats_item['statistics'].get('commentCount', 0)),\n",
    "                    'duration': stats_item['contentDetails']['duration'],\n",
    "                }\n",
    "                \n",
    "                resource_id = insert_youtube_resource(video_data, skill, query)\n",
    "                if resource_id:\n",
    "                    skill_resources += 1\n",
    "                    total_resources += 1\n",
    "            \n",
    "            time.sleep(1)  # Rate limiting\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó Query '{query}' failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if skill_resources > 0:\n",
    "        print(f\"  ‚úì Added {skill_resources} videos\")\n",
    "        total_inserted += 1\n",
    "    else:\n",
    "        print(f\"  ‚ö† No videos added\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úì Skills processed: {total_inserted}/{len(soft_skills)}\")\n",
    "print(f\"‚úì Total YouTube videos inserted: {total_resources}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74d498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
